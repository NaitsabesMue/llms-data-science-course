# Large Language Models in Data Science (WIP)

This repository contains materials for a **21-hour lecture** titled:

> **Large Language Models in Data Science**  
> *Prompting, Fine-Tuning, Retrieval & Applied Use Cases*

---

## ⚠️ Status: Work in Progress

This course is under active development. Materials, notebooks, and project templates will evolve over time as we adapt content to student feedback and available tooling.

---

## 🎯 Course Objectives

- Understand the architecture and functioning of large language models (LLMs)
- Learn prompt engineering and retrieval-augmented generation (RAG)
- Explore lightweight fine-tuning techniques (e.g., LoRA)
- Apply LLMs to real data science tasks: analysis, reporting, feature generation, and code assistance

---

## 📚 Structure

- **Language**: English  
- **Audience**: Final-year data science students with strong math background  
- **Total Time**: 21h  
  - Lectures: ~7h  
  - Labs: ~7h  
  - Hackathon: ~7h (final evaluation)

---

## 💻 Content

| Folder | Description |
|--------|-------------|
| `slides/` | LaTeX slide decks for all lectures |
| `labs/` | Jupyter notebooks for hands-on experimentation |
| `examples/` | Prebuilt pipelines: OpenAI API, RAG demos, etc. |
| `projects/` | Hackathon templates and ideas |

---

## 🧪 Final Evaluation: Hackathon

The final mark (out of 20) will be based on participation in a **group hackathon** (teams of 1 to 5 participants). Each team will present a project that uses LLMs in a data science context.

### 🔍 Evaluation Breakdown (4 x 5 points)

| Criterion | Description |
|----------|-------------|
| **1. Use Case & Applications (5 pts)** | Relevance, originality, and potential future usefulness of the proposed use case |
| **2. Code Cleanliness (5 pts)** | Code readability, organization, comments, modularity, and reproducibility |
| **3. Lecture Integration (5 pts)** | Use of concepts covered in the course: prompting, fine-tuning, RAG, etc. |
| **4. Presentation (5 pts)** | Clarity, conciseness, visuals, and ability to explain design decisions |

> 💡 Your final score out of 20 is your **official course grade**.

---

## 📅 Timeline

Materials and project themes will be released progressively over the semester. Stay tuned for:
- Weekly labs and reference notebooks
- Suggested datasets and use cases
- Hackathon timeline and submission deadlines

---

## 🗓️ Weekly Materials

### Week 1 – LLMs: A Primer
- Slides: `slides/week_1_intro.tex`
- Lab: `labs/week_1_tokenization.ipynb`
- Readings: [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/), [OpenAI GPT Models Documentation](https://platform.openai.com/docs/guides/gpt), [Attention Is All You Need](https://arxiv.org/abs/1706.03762)



---

## 📬 Contact

Instructor: _Sebastian Mueller_  
University: _Aix-Marseille Université_  
Course code: _TBD_
