# Large Language Models in Data Science (WIP)

This repository contains materials for a **21-hour lecture** titled:

> **Large Language Models in Data Science**  
> *Prompting, Fine-Tuning, Retrieval & Applied Use Cases*

---

## ‚ö†Ô∏è Status: Work in Progress

This course is under active development. Materials, notebooks, and project templates will evolve over time as we adapt content to student feedback and available tooling.

---

## üéØ Course Objectives

- Understand the architecture and functioning of large language models (LLMs)
- Learn prompt engineering and retrieval-augmented generation (RAG)
- Explore lightweight fine-tuning techniques (e.g., LoRA)
- Apply LLMs to real data science tasks: analysis, reporting, feature generation, and code assistance

---

## üìö Structure

- **Language**: English  
- **Audience**: Final-year data science students with strong math background  
- **Total Time**: 21h  
  - Lectures: ~7h  
  - Labs: ~7h  
  - Hackathon: ~7h (final evaluation)

---

## üíª Content

| Folder | Description |
|--------|-------------|
| `slides/` | LaTeX slide decks for all lectures |
| `labs/` | Jupyter notebooks for hands-on experimentation |
| `examples/` | Prebuilt pipelines: OpenAI API, RAG demos, etc. |
| `projects/` | Hackathon templates and ideas |

---

## üß™ Final Evaluation: Hackathon

The final mark (out of 20) will be based on participation in a **group hackathon** (teams of 1 to 5 participants). Each team will present a project that uses LLMs in a data science context.

### üîç Evaluation Breakdown (4 x 5 points)

| Criterion | Description |
|----------|-------------|
| **1. Use Case & Applications (5 pts)** | Relevance, originality, and potential future usefulness of the proposed use case |
| **2. Code Cleanliness (5 pts)** | Code readability, organization, comments, modularity, and reproducibility |
| **3. Lecture Integration (5 pts)** | Use of concepts covered in the course: prompting, fine-tuning, RAG, etc. |
| **4. Presentation (5 pts)** | Clarity, conciseness, visuals, and ability to explain design decisions |

> üí° Your final score out of 20 is your **official course grade**.

---

## üìÖ Timeline

Materials and project themes will be released progressively over the semester. Stay tuned for:
- Weekly labs and reference notebooks
- Suggested datasets and use cases
- Hackathon timeline and submission deadlines

---

## üóìÔ∏è Weekly Materials

### Week 1 ‚Äì LLMs: A Primer
- Slides: `slides/week_1_intro.tex`
- Lab: `labs/week_1_tokenization.ipynb`
- Readings: [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/), [OpenAI GPT Models Documentation](https://platform.openai.com/docs/guides/gpt), [Attention Is All You Need](https://arxiv.org/abs/1706.03762)

### Week 2 ‚Äì Prompt Engineering
- Slides: `slides/week_2_prompting.tex`
- Lab: `labs/week_2_prompting.ipynb`
- Readings: [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering), [Google Gemini Prompting Guide](https://ai.google.dev/gemini-api/docs/prompting), [Chain-of-Thought Prompting Elicits Reasoning](https://arxiv.org/abs/2202.12837)

### Week 3 ‚Äì Fine-Tuning & LoRA
- Slides: `slides/week_3_finetuning.tex`
- Lab: `labs/week_3_finetuning.ipynb`
- Readings: [HuggingFace PEFT Documentation](https://huggingface.co/docs/peft), [HuggingFace Course](https://huggingface.co/course), [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)

### Week 4 ‚Äì LLMs in Data Science
- Slides: `slides/week_4_data_science.tex`
- Lab: `labs/week_4_llm_ds.ipynb`
- Readings: [OpenAI Cookbook (Tabular Examples)](https://github.com/openai/openai-cookbook), [PandasAI](https://github.com/gventuri/pandas-ai), [Code Interpreter in the Wild](https://arxiv.org/abs/2310.01228)

### Week 5 ‚Äì Retrieval-Augmented Generation
- Slides: `slides/week_5_rag.tex`
- Lab: `labs/week_5_rag.ipynb`
- Readings: [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings), [Supabase pgvector RAG Tutorial](https://supabase.com/blog/openai-embeddings-postgres-vector), [LangChain Question Answering Guide](https://python.langchain.com/docs/use_cases/question_answering/)

### Week 6 ‚Äì Mini-Project Sprint
- Slides: `slides/week_6_project.tex`
- Lab: `labs/week_6_project.ipynb`
- Readings: [OpenAI Cookbook](https://github.com/openai/openai-cookbook), [HuggingFace PEFT Examples](https://huggingface.co/docs/peft), [LangChain Documentation](https://python.langchain.com/)

---

## üì¨ Contact

Instructor: _Sebastian Mueller_  
University: _Aix-Marseille Universit√©_  
Course code: _TBD_