{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 3 Lab: Prompting for Effective LLM Use\n",
        "\n",
        "Focus: clear rules, roles (system vs. user), separating data from instructions, formatting outputs for parsing, two-step prompting, and a small optional EDA demo.\n",
        "\n",
        "Default model: gemini-2.5-flash-live (fast and free)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Setup\n",
        "\n",
        "- pip install google-generativeai python-dotenv pandas numpy seaborn matplotlib scipy\n",
        "\n",
        "Put your API key in .env as GEMINI_API_KEY=... and restart the kernel if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import os, json, textwrap\n",
        "from typing import Any, Dict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
        "assert GEMINI_API_KEY, 'Please set GEMINI_API_KEY in your environment or .env file.'\n",
        "\n",
        "import google.generativeai as genai\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "MODEL_NAME = os.getenv('GEMINI_MODEL', 'gemini-2.5-flash')\n",
        "GEN_CONFIG = genai.GenerationConfig(temperature=0.3, max_output_tokens=800)\n",
        "GEN_CONFIG_EXTENDED = genai.GenerationConfig(temperature=0.3, max_output_tokens=5000)\n",
        "\n",
        "model_default = genai.GenerativeModel(MODEL_NAME)\n",
        "def make_model(system_instruction: str | None = None):\n",
        "    return genai.GenerativeModel(MODEL_NAME, system_instruction=system_instruction)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Clear rules for prompting\n",
        "\n",
        "- Be specific: ask only for what you need; set scope and length.\n",
        "- State a role: use a system instruction for role and constraints.\n",
        "- Separate parts: instructions, data, and output format.\n",
        "- Format outputs: require strict JSON or a fenced code block.\n",
        "- Acceptance criteria: add a checklist and self-verify.\n",
        "- Few-shot (minimal): one short example can anchor style."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dabe0be2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Bad Prompt: Vague and unstructured ---\n",
        "bad_prompt = \"Tell me about large language models.\"\n",
        "print(\"--- Bad Prompt ---\")\n",
        "print(model_default.generate_content(bad_prompt, generation_config=GEN_CONFIG_EXTENDED).text)\n",
        "\n",
        "\n",
        "# --- Good Prompt: Clear, role-based, and structured ---\n",
        "good_prompt = textwrap.dedent('''\n",
        "    You are an expert technical writer.\n",
        "    Explain the concept of \"Large Language Models\" to a university student.\n",
        "    - Start with a one-sentence definition.\n",
        "    - Provide three key bullet points on how they work.\n",
        "    - Limit the total response to under 100 words.\n",
        "''')\n",
        "print(\"\\n--- Good Prompt ---\")\n",
        "print(model_default.generate_content(good_prompt, generation_config=GEN_CONFIG).text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a19c4fa",
      "metadata": {},
      "source": [
        "### Exercise \n",
        "Improve the following vague prompt by applying at least three of the \"clear rules\" (e.g., add a role, specify the format, set constraints).\n",
        "\n",
        "**Vague prompt:** `\"Why should I learn data science?\"`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Role prompting changes outcomes (system vs. user)\n",
        "\n",
        "We keep the user prompt identical and only change the system instruction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PROMPT = 'In one sentence, what do you think about skateboarding?'\n",
        "\n",
        "resp_plain = model_default.generate_content(PROMPT, generation_config=GEN_CONFIG)\n",
        "print('No system instruction:', resp_plain.text)\n",
        "\n",
        "model_cat = make_model('You are a cat.')\n",
        "resp_cat = model_cat.generate_content(PROMPT, generation_config=GEN_CONFIG)\n",
        "print('System: You are a cat.', resp_cat.text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73422a62",
      "metadata": {},
      "source": [
        "### Exercise \n",
        "Using the same `PROMPT` about skateboarding, create a new model with the system instruction `\"You are a worried parent.\"` and generate a response. How does it differ from the \"cat\" and default responses?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Separate data from instructions\n",
        "\n",
        "Keep your instructions stable and swap data safely using delimiters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "instructions = textwrap.dedent('''\n",
        "Summarize the data in one short sentence and produce 3 topical tags.\n",
        "Return strict JSON with keys summary (str) and tags (list of str).\n",
        "''').strip()\n",
        "data_block = textwrap.dedent('''<data>\n",
        "Skateboarding participation has risen globally over the past decade,\n",
        "with growing inclusion in major events and broader demographics. During the last olympic games, skateboarding made its debut,\n",
        "highlighting its increasing recognition as a competitive sport. The culture around skateboarding continues to evolve,\n",
        "influencing fashion, music, and lifestyle trends worldwide.\n",
        "</data>''').strip()\n",
        "\n",
        "prompt = f'Instructions: {instructions}{data_block}'\n",
        "resp = model_default.generate_content(prompt, generation_config=GEN_CONFIG)\n",
        "text = resp.text\n",
        "print(text)\n",
        "# Strip markdown fences if the model added them\n",
        "if text.strip().startswith(\"```json\"):\n",
        "    text = text.strip().removeprefix(\"```json\\n\").removesuffix(\"\\n```\")\n",
        "try:\n",
        "    parsed = json.loads(text)\n",
        "    print('Parsed:', parsed)\n",
        "except Exception as e:\n",
        "    print('Parsing failed; consider asking the model to fix format.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f920ea1a",
      "metadata": {},
      "source": [
        "### Exercise \n",
        "Use the `instructions` variable from the example above, but replace the `data_block` with a new paragraph about a topic of your choice. Verify that the model still follows the instructions and produces the correct JSON output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Formatting outputs for parsing\n",
        "\n",
        "Ask for strict JSON and validate with json.loads. If parsing fails, ask the model to fix the format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "schema = 'title: str; bullets: list[str]'\n",
        "prompt = (\n",
        "    'System: Return strict JSON with keys title (str) and bullets (list[str]).'\n",
        "    'User:'\n",
        "    '- Task: Summarize why clear prompts matter for data science.'\n",
        "    '- Length: Title + 3 bullets.'\n",
        "    f'- Output: {schema}'\n",
        ")\n",
        "resp = model_default.generate_content(prompt, generation_config=GEN_CONFIG)\n",
        "text = resp.text or ''\n",
        "print(text)\n",
        "\n",
        "# Strip markdown fences if the model added them\n",
        "if text.strip().startswith(\"```json\"):\n",
        "    text = text.strip().removeprefix(\"```json\\n\").removesuffix(\"\\n```\")\n",
        "\n",
        "try:\n",
        "    obj = json.loads(text)\n",
        "    print('Valid JSON with', len(obj.get('bullets', [])), 'bullets')\n",
        "except json.JSONDecodeError as e:\n",
        "    print('JSON parse error:', e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7a6659d",
      "metadata": {},
      "source": [
        "### Exercise \n",
        "Modify the prompt to request a different JSON schema. Ask the model to return an object with two keys: `topic` (a string) and `key_takeaways` (a list of exactly two strings)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Two-step prompting (prompt-writer)\n",
        "\n",
        "Use the model to craft the prompt first, then run that prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "task = textwrap.dedent('''\n",
        "Write exactly 5 concise bullets for an EDA plan on a churn dataset\n",
        "with columns: age, tenure_months, monthly_charges, contract_type, churn.\n",
        "''').strip()\n",
        "\n",
        "prompt_writer = textwrap.dedent('''\n",
        "You are a prompt engineer. Draft a clear, minimal prompt for another LLM to:\n",
        "- Role: senior data scientist\n",
        "- Task: {TASK}\n",
        "- Output: exactly 5 bullets in plain text\n",
        "- Constraints: be specific, no extra commentary\n",
        "Return ONLY the prompt text that I can paste into the other model.\n",
        "''').format(TASK=task)\n",
        "\n",
        "response = model_default.generate_content(prompt_writer, generation_config=GEN_CONFIG_EXTENDED)\n",
        "draft = response.text if response.text else \"Error: No response generated\"\n",
        "print('--- Drafted prompt ---')\n",
        "print(draft)\n",
        "\n",
        "if draft != \"Error: No response generated\":\n",
        "\tresponse = model_default.generate_content(draft, generation_config=GEN_CONFIG_EXTENDED)\n",
        "\tresult = response.text if response.text else \"Error: No response generated\"\n",
        "\tprint('\\n--- Result ---')\n",
        "\tprint(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1c5d825",
      "metadata": {},
      "source": [
        "### Exercise\n",
        "Use the two-step \"prompt-writer\" pattern for a different task. First, have the model generate a prompt that asks another LLM to write a four-line poem about Marseille. Then, execute the generated prompt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Optional: quick EDA demo (code generation)\n",
        "\n",
        "We generate a small dataset and ask the model for a minimal analyze(df) function.\n",
        "We require ONLY raw Python code (no fences) to simplify execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rng = np.random.default_rng(42)\n",
        "n = 600\n",
        "age = rng.integers(18, 75, size=n)\n",
        "tenure = rng.integers(1, 72, size=n)\n",
        "monthly = rng.normal(65, 20, size=n).clip(5, 200)\n",
        "contract_type = rng.choice(['month-to-month','one-year','two-year'], size=n, p=[0.55,0.25,0.20])\n",
        "p_churn = 1/(1+np.exp(-(0.35 - 0.003*tenure - 0.10*(contract_type=='two-year') - 0.05*(contract_type=='one-year') + 0.0015*(monthly-65))))\n",
        "churn = rng.binomial(1, p_churn)\n",
        "df = pd.DataFrame({'age': age, 'tenure_months': tenure, 'monthly_charges': monthly, 'contract_type': contract_type, 'churn': churn})\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eda_prompt = (\n",
        "    'Return ONLY Python code (no fences) defining a function `def analyze(df):`. '\n",
        "    'Inside the function: '\n",
        "    '1) Use pandas, seaborn, and matplotlib to perform a basic EDA. '\n",
        "    '2) Print the results of df.describe(). '\n",
        "    '3) Create two interesting plots (e.g., a histogram and a boxplot) to visualize the data. '\n",
        "    '4) Do NOT call plt.show() or plt.close() inside the function. '\n",
        "    '5) The function should not return any value. '\n",
        ")\n",
        "\n",
        "response = model_default.generate_content(eda_prompt, generation_config=GEN_CONFIG_EXTENDED, safety_settings=safety_settings)\n",
        "\n",
        "# Check if the response was blocked before proceeding\n",
        "if not response.candidates:\n",
        "    print(\"Code generation failed. The response was blocked.\")\n",
        "    print(\"Reason:\", response.prompt_feedback)\n",
        "else:\n",
        "    try:\n",
        "        eda_code = response.text\n",
        "        # Strip markdown fences if the model added them\n",
        "        if eda_code.strip().startswith(\"```python\"):\n",
        "            eda_code = eda_code.strip().removeprefix(\"```python\\n\").removesuffix(\"\\n```\")\n",
        "        # Add a print statement to debug the generated code\n",
        "        print(\"--- Generated Code ---\")\n",
        "        print(eda_code)\n",
        "        print(\"----------------------\")\n",
        "\n",
        "        # The sandbox provides the allowed modules.\n",
        "        # We  allow standard functions.\n",
        "        sandbox = {'pd': pd, 'np': np, 'sns': sns, 'plt': plt, 'stats': stats}\n",
        "        exec(compile(eda_code, '<generated>', 'exec'), sandbox, sandbox)\n",
        "        \n",
        "        assert 'analyze' in sandbox, 'The generated code did not define the \"analyze\" function.'\n",
        "        \n",
        "        result = sandbox['analyze'](df)\n",
        "        print(\"\\n--- Analysis Results ---\")\n",
        "        print({k: ('ok' if not isinstance(v, (int, float, str)) else v) for k, v in result.items()})\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn error occurred while executing the generated code: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc70cc43",
      "metadata": {},
      "source": [
        "### Exercice\n",
        "Play with the above code generation model. How far can you push it?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1589438",
      "metadata": {},
      "source": [
        "### Exercice\n",
        "Use the techniques of your choice to analyse the dataset `\\data\\weightHeightSex.txt`.  "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (venvLLMDS)",
      "language": "python",
      "name": "venvllmds"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
