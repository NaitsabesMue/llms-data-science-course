{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "783618be",
   "metadata": {},
   "source": [
    "# Week 4 Lab: Building the AMU Chatbot Brain\n",
    "\n",
    "Your mission today, should you choose to accept it, is to build the \"brain\" for a new AMU chatbot. \n",
    "\n",
    "The goal is **Intent Classification**: We need to take a student's query (e.g., *\"Où est mon emploi du temps?\"*) and map it to a specific service from the AMU portal (e.g., `get_schedule`).\n",
    "\n",
    "Today, we will build and compare **four** different \"brains\" to see how they perform. We'll compare them on two key metrics:\n",
    "1.  **Accuracy**: Does it get the right answer?\n",
    "2.  **Latency**: How fast is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60d62b8",
   "metadata": {},
   "source": [
    "## Module 0: Setup\n",
    "\n",
    "First, let's install the libraries we'll need. We'll use `transformers`, `datasets` (for later), `scikit-learn` for our classic ML model, `pandas` for our final analysis, and `sentence-transformers` (which is built on top of `transformers`) for high-quality embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5002db66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (4.57.1)\n",
      "Requirement already satisfied: datasets in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (4.2.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (1.7.2)\n",
      "Requirement already satisfied: pandas in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (2.3.3)\n",
      "Requirement already satisfied: sentence-transformers in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (5.1.1)\n",
      "Requirement already satisfied: accelerate in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (1.10.1)\n",
      "Requirement already satisfied: torch in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from transformers) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: anyio in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: Pillow in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: psutil in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from accelerate) (7.1.0)\n",
      "Requirement already satisfied: setuptools in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U transformers datasets scikit-learn pandas sentence-transformers accelerate torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e6d8b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "# A helper to print things nicely\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdc3b12",
   "metadata": {},
   "source": [
    "## Module 1: The Dataset - Our \"Ground Truth\"\n",
    "\n",
    "Before we can build a classifier, we need data! Based on the AMU portal, we'll define 5 key intents. We'll then create a small, synthetic dataset of *training* queries and *testing* queries.\n",
    "\n",
    "**Our 5 Intents:**\n",
    "1.  `get_schedule` (for \"Planning des cours (ADE)\")\n",
    "2.  `check_email` (for \"Ma messagerie\")\n",
    "3.  `register_classes` (for \"Inscriptions pédagogiques (IP)\")\n",
    "4.  `get_student_card` (for \"Ma carte AMU\")\n",
    "5.  `find_library_info` (for \"BU\" / \"Compte Lecteur BU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cc2b65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Training Data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "4193df1b-fed1-44e9-a3d5-9f30218f37e2",
       "rows": [
        [
         "0",
         "Où est mon emploi du temps?",
         "get_schedule"
        ],
        [
         "1",
         "Je veux voir mes cours de demain",
         "get_schedule"
        ],
        [
         "2",
         "Afficher mon planning de la semaine",
         "get_schedule"
        ],
        [
         "3",
         "J'ai un nouveau mail?",
         "check_email"
        ],
        [
         "4",
         "Ouvrir ma messagerie",
         "check_email"
        ],
        [
         "5",
         "Boite de réception",
         "check_email"
        ],
        [
         "6",
         "Comment je m'inscris à un cours?",
         "register_classes"
        ],
        [
         "7",
         "Où sont les inscriptions pédas?",
         "register_classes"
        ],
        [
         "8",
         "Je dois faire mon IP",
         "register_classes"
        ],
        [
         "9",
         "J'ai perdu ma carte étudiante",
         "get_student_card"
        ],
        [
         "10",
         "Refaire ma carte AMU",
         "get_student_card"
        ],
        [
         "11",
         "La BU est ouverte?",
         "find_library_info"
        ],
        [
         "12",
         "Quels sont les horaires de la bibliothèque?",
         "find_library_info"
        ],
        [
         "13",
         "Je veux emprunter un livre",
         "find_library_info"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 14
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Où est mon emploi du temps?</td>\n",
       "      <td>get_schedule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Je veux voir mes cours de demain</td>\n",
       "      <td>get_schedule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afficher mon planning de la semaine</td>\n",
       "      <td>get_schedule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J'ai un nouveau mail?</td>\n",
       "      <td>check_email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ouvrir ma messagerie</td>\n",
       "      <td>check_email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Boite de réception</td>\n",
       "      <td>check_email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Comment je m'inscris à un cours?</td>\n",
       "      <td>register_classes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Où sont les inscriptions pédas?</td>\n",
       "      <td>register_classes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Je dois faire mon IP</td>\n",
       "      <td>register_classes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>J'ai perdu ma carte étudiante</td>\n",
       "      <td>get_student_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Refaire ma carte AMU</td>\n",
       "      <td>get_student_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>La BU est ouverte?</td>\n",
       "      <td>find_library_info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Quels sont les horaires de la bibliothèque?</td>\n",
       "      <td>find_library_info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Je veux emprunter un livre</td>\n",
       "      <td>find_library_info</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text              label\n",
       "0                   Où est mon emploi du temps?       get_schedule\n",
       "1              Je veux voir mes cours de demain       get_schedule\n",
       "2           Afficher mon planning de la semaine       get_schedule\n",
       "3                         J'ai un nouveau mail?        check_email\n",
       "4                          Ouvrir ma messagerie        check_email\n",
       "5                            Boite de réception        check_email\n",
       "6              Comment je m'inscris à un cours?   register_classes\n",
       "7               Où sont les inscriptions pédas?   register_classes\n",
       "8                          Je dois faire mon IP   register_classes\n",
       "9                 J'ai perdu ma carte étudiante   get_student_card\n",
       "10                         Refaire ma carte AMU   get_student_card\n",
       "11                           La BU est ouverte?  find_library_info\n",
       "12  Quels sont les horaires de la bibliothèque?  find_library_info\n",
       "13                   Je veux emprunter un livre  find_library_info"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Test Data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "cc1fc30d-0a58-44c7-91ac-c0fb2c83b553",
       "rows": [
        [
         "0",
         "C'est quand mon prochain TD?",
         "get_schedule"
        ],
        [
         "1",
         "Ouvrir la boite de réception",
         "check_email"
        ],
        [
         "2",
         "Je veux m'inscrire en L3",
         "register_classes"
        ],
        [
         "3",
         "Ma carte est cassée",
         "get_student_card"
        ],
        [
         "4",
         "Les horaires de la BU St Charles",
         "find_library_info"
        ],
        [
         "5",
         "Quelle salle pour mon cours de 10h?",
         "get_schedule"
        ],
        [
         "6",
         "J'ai reçu un email important?",
         "check_email"
        ],
        [
         "7",
         "C'est quand les IP?",
         "register_classes"
        ],
        [
         "8",
         "Où est-ce que je peux imprimer avec ma carte?",
         "get_student_card"
        ],
        [
         "9",
         "Comment réserver un livre à la BU?",
         "find_library_info"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C'est quand mon prochain TD?</td>\n",
       "      <td>get_schedule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ouvrir la boite de réception</td>\n",
       "      <td>check_email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Je veux m'inscrire en L3</td>\n",
       "      <td>register_classes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ma carte est cassée</td>\n",
       "      <td>get_student_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Les horaires de la BU St Charles</td>\n",
       "      <td>find_library_info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Quelle salle pour mon cours de 10h?</td>\n",
       "      <td>get_schedule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>J'ai reçu un email important?</td>\n",
       "      <td>check_email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C'est quand les IP?</td>\n",
       "      <td>register_classes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Où est-ce que je peux imprimer avec ma carte?</td>\n",
       "      <td>get_student_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Comment réserver un livre à la BU?</td>\n",
       "      <td>find_library_info</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text              label\n",
       "0                   C'est quand mon prochain TD?       get_schedule\n",
       "1                   Ouvrir la boite de réception        check_email\n",
       "2                       Je veux m'inscrire en L3   register_classes\n",
       "3                            Ma carte est cassée   get_student_card\n",
       "4               Les horaires de la BU St Charles  find_library_info\n",
       "5            Quelle salle pour mon cours de 10h?       get_schedule\n",
       "6                  J'ai reçu un email important?        check_email\n",
       "7                            C'est quand les IP?   register_classes\n",
       "8  Où est-ce que je peux imprimer avec ma carte?   get_student_card\n",
       "9             Comment réserver un livre à la BU?  find_library_info"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here is our training data. We'll use this to train Classifier 2.\n",
    "train_data = [\n",
    "    {\"text\": \"Où est mon emploi du temps?\", \"label\": \"get_schedule\"},\n",
    "    {\"text\": \"Je veux voir mes cours de demain\", \"label\": \"get_schedule\"},\n",
    "    {\"text\": \"Afficher mon planning de la semaine\", \"label\": \"get_schedule\"},\n",
    "    {\"text\": \"J'ai un nouveau mail?\", \"label\": \"check_email\"},\n",
    "    {\"text\": \"Ouvrir ma messagerie\", \"label\": \"check_email\"},\n",
    "    {\"text\": \"Boite de réception\", \"label\": \"check_email\"},\n",
    "    {\"text\": \"Comment je m'inscris à un cours?\", \"label\": \"register_classes\"},\n",
    "    {\"text\": \"Où sont les inscriptions pédas?\", \"label\": \"register_classes\"},\n",
    "    {\"text\": \"Je dois faire mon IP\", \"label\": \"register_classes\"},\n",
    "    {\"text\": \"J'ai perdu ma carte étudiante\", \"label\": \"get_student_card\"},\n",
    "    {\"text\": \"Refaire ma carte AMU\", \"label\": \"get_student_card\"},\n",
    "    {\"text\": \"La BU est ouverte?\", \"label\": \"find_library_info\"},\n",
    "    {\"text\": \"Quels sont les horaires de la bibliothèque?\", \"label\": \"find_library_info\"},\n",
    "    {\"text\": \"Je veux emprunter un livre\", \"label\": \"find_library_info\"}\n",
    "]\n",
    "\n",
    "# Here is our test data. We'll use this to evaluate ALL classifiers.\n",
    "test_data = [\n",
    "    {\"text\": \"C'est quand mon prochain TD?\", \"label\": \"get_schedule\"},\n",
    "    {\"text\": \"Ouvrir la boite de réception\", \"label\": \"check_email\"},\n",
    "    {\"text\": \"Je veux m'inscrire en L3\", \"label\": \"register_classes\"},\n",
    "    {\"text\": \"Ma carte est cassée\", \"label\": \"get_student_card\"},\n",
    "    {\"text\": \"Les horaires de la BU St Charles\", \"label\": \"find_library_info\"},\n",
    "    {\"text\": \"Quelle salle pour mon cours de 10h?\", \"label\": \"get_schedule\"},\n",
    "    {\"text\": \"J'ai reçu un email important?\", \"label\": \"check_email\"},\n",
    "    {\"text\": \"C'est quand les IP?\", \"label\": \"register_classes\"},\n",
    "    {\"text\": \"Où est-ce que je peux imprimer avec ma carte?\", \"label\": \"get_student_card\"},\n",
    "    {\"text\": \"Comment réserver un livre à la BU?\", \"label\": \"find_library_info\"}\n",
    "]\n",
    "\n",
    "# Let's put them in a DataFrame to visualize\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "display(Markdown(\"### Training Data\"))\n",
    "display(train_df)\n",
    "display(Markdown(\"### Test Data\"))\n",
    "display(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe66f4e",
   "metadata": {},
   "source": [
    "--- \n",
    "## Module 2: Classifier 1 - The Regex Baseline\n",
    "\n",
    "Our first model isn't a model at all! It's a simple function using Regular Expressions (or just `if/in` statements) to check for keywords.\n",
    "\n",
    "**Why?** It's extremely fast, easy to understand, and a perfect baseline. Never underestimate the power of a simple, robust baseline.\n",
    "\n",
    "### ✏️ Your Exercise:\n",
    "\n",
    "Complete the `classify_regex` function below. We've given you a `keywords` dictionary to start with. Your function should take a `query`, convert it to lowercase, and check if any keywords for an intent are present. It should return the *first* intent it matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b355260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'C'est quand mon prochain TD?'\n",
      "Prediction: get_schedule\n",
      "Correct: True\n"
     ]
    }
   ],
   "source": [
    "keywords = {\n",
    "    \"get_schedule\": [\"planning\", \"emploi du temps\", \"cours\", \"salle\", \"td\", \"cm\"],\n",
    "    \"check_email\": [\"mail\", \"messagerie\", \"email\", \"boite de réception\"],\n",
    "    \"register_classes\": [\"inscription\", \"ip\", \"péda\", \"inscrire\"],\n",
    "    \"get_student_card\": [\"carte\", \"amu\"],\n",
    "    \"find_library_info\": [\"bu\", \"bibliothèque\", \"livre\", \"emprunter\"]\n",
    "}\n",
    "\n",
    "def classify_regex(query):\n",
    "    query_low = query.lower()\n",
    "    for intent, kws in keywords.items():\n",
    "        for kw in kws:\n",
    "            if kw in query_low:\n",
    "                return intent\n",
    "    return \"unknown\" # Default if no keyword is found\n",
    "\n",
    "# --- Test your function ---\n",
    "test_query = test_data[0]['text']\n",
    "prediction = classify_regex(test_query)\n",
    "\n",
    "print(f\"Query: '{test_query}'\")\n",
    "print(f\"Prediction: {prediction}\")\n",
    "print(f\"Correct: {prediction == test_data[0]['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cfac64",
   "metadata": {},
   "source": [
    "### Exploration:\n",
    "Look at the `keywords` for `get_student_card`. The keyword `\"amu\"` is present, but what if the query is *\"Comment contacter le secrétariat d'AMU?\"*? This would be a false positive! How would you make your regex more specific to avoid this? (This is the fundamental limit of regex)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321363f1",
   "metadata": {},
   "source": [
    "---\n",
    "## Module 3: Classifier 2 - Embeddings + Logistic Regression\n",
    "\n",
    "This is our \"classic ML\" approach. We will use a powerful pretrained model from Hugging Face to **extract features** (embeddings) from our text. Then, we'll feed these numerical features into a very simple and fast `scikit-learn` classifier, `LogisticRegression`.\n",
    "\n",
    "This is a perfect example of mixing the \"low-level\" `transformers` world with the `scikit-learn` ecosystem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f9565f",
   "metadata": {},
   "source": [
    "### Step 3.1: Load the Embedding Model\n",
    "\n",
    "We'll use a `sentence-transformer` model. These models are specifically fine-tuned to create high-quality embeddings for tasks like comparison and classification. We'll use a multilingual one since our queries are in French.\n",
    "\n",
    "### ✏️ Your Exercise:\n",
    "\n",
    "Load the `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` model. We'll create a helper function `get_embedding` that takes a list of texts and returns their embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "364f105d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n",
      "Model loaded!\n",
      "\n",
      "Successfully converted 2 texts into embeddings.\n",
      "Shape of embeddings: (2, 384)\n"
     ]
    }
   ],
   "source": [
    "# Load the embedding model\n",
    "# This will download the model the first time you run it\n",
    "print(\"Loading embedding model...\")\n",
    "embed_model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "print(\"Model loaded!\")\n",
    "\n",
    "def get_embeddings(text_list):\n",
    "    # .encode() is the main function of SentenceTransformer\n",
    "    # It handles tokenization, model forward pass, and pooling all in one!\n",
    "    return embed_model.encode(text_list)\n",
    "\n",
    "# --- Test your function ---\n",
    "example_texts = [train_data[0]['text'], train_data[3]['text']]\n",
    "example_embeddings = get_embeddings(example_texts)\n",
    "\n",
    "print(f\"\\nSuccessfully converted {len(example_texts)} texts into embeddings.\")\n",
    "print(f\"Shape of embeddings: {example_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdff9e1c",
   "metadata": {},
   "source": [
    "### Step 3.2: Train the Classifier\n",
    "\n",
    "Now we'll use our `train_data` to train a `LogisticRegression` model.\n",
    "\n",
    "### Your Exercise:\n",
    "1.  Create `X_train` by getting the embeddings for all texts in `train_data`.\n",
    "2.  Create `y_train` by getting the corresponding labels from `train_data`.\n",
    "3.  Initialize and `fit` a `LogisticRegression` classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d412f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training embeddings...\n",
      "Created X_train with shape (14, 384) and y_train with 14 labels\n",
      "Training Logistic Regression classifier...\n",
      "Classifier trained!\n",
      "\n",
      "Query: 'C'est quand mon prochain TD?'\n",
      "Prediction: get_schedule\n",
      "Correct: True\n"
     ]
    }
   ],
   "source": [
    "# 1. Create X_train (the features)\n",
    "print(\"Creating training embeddings...\")\n",
    "train_texts = [item['text'] for item in train_data]\n",
    "X_train = get_embeddings(train_texts)\n",
    "\n",
    "# 2. Create y_train (the labels)\n",
    "y_train = [item['label'] for item in train_data]\n",
    "\n",
    "print(f\"Created X_train with shape {X_train.shape} and y_train with {len(y_train)} labels\")\n",
    "\n",
    "# 3. Train the classifier\n",
    "print(\"Training Logistic Regression classifier...\")\n",
    "clf_logreg = LogisticRegression(max_iter=1000) # Use more iterations for convergence\n",
    "clf_logreg.fit(X_train, y_train)\n",
    "print(\"Classifier trained!\")\n",
    "\n",
    "# --- Test your classifier ---\n",
    "test_query = test_data[0]['text']\n",
    "test_embedding = get_embeddings([test_query]) # Note: must be a list!\n",
    "\n",
    "prediction = clf_logreg.predict(test_embedding)[0]\n",
    "print(f\"\\nQuery: '{test_query}'\")\n",
    "print(f\"Prediction: {prediction}\")\n",
    "print(f\"Correct: {prediction == test_data[0]['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b08707",
   "metadata": {},
   "source": [
    "### Exploration:\n",
    "How much better does this model get with more data? Try adding 5-10 more examples to `train_data` and re-run this module. Does the accuracy on the test set improve? What other `scikit-learn` classifiers could you try instead of `LogisticRegression`? (e.g., `SVC`, `RandomForestClassifier`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50b3aa4",
   "metadata": {},
   "source": [
    "---\n",
    "## Module 4: Classifier 3 - The Zero-Shot Pipeline\n",
    "\n",
    "This is the **high-level API** from your lecture. We'll use a `zero-shot-classification` pipeline. This model was trained on a Natural Language Inference (NLI) task, which allows it to determine if a \"premise\" (our query) entails a \"hypothesis\" (our candidate labels).\n",
    "\n",
    "**The best part?** No training data required! \n",
    "\n",
    "### Your Exercise:\n",
    "1.  Load a `zero-shot-classification` pipeline. We'll use `MoritzLaurer/mDeBERTa-v3-base-mnli-xnli`, which is a strong multilingual model.\n",
    "2.  Define your `candidate_labels`. **Pro-tip**: These are *descriptions*, not just the short names. This helps the model.\n",
    "3.  Call the classifier on a test query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef7df92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading zero-shot pipeline... (This may take a moment)\n",
      "  \u001b[2m2025-10-20T09:13:37.454271Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 500. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"01K80EAHWMT34PCY766SDYKJK5\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:227\n",
      "\n",
      "  \u001b[2m2025-10-20T09:13:37.454289Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #0. Sleeping 384.375198ms before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n",
      "  \u001b[2m2025-10-20T09:13:37.944870Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 500. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"01K80EAJBZ274FX0QDSWJN1F5V\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:227\n",
      "\n",
      "  \u001b[2m2025-10-20T09:13:37.944925Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #1. Sleeping 2.88131406s before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n",
      "  \u001b[2m2025-10-20T09:13:40.934128Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 500. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"01K80EAN9B1XEEM0PPJVJQHBEH\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:227\n",
      "\n",
      "  \u001b[2m2025-10-20T09:13:40.934233Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #2. Sleeping 8.071255857s before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n",
      "  \u001b[2m2025-10-20T09:13:49.115083Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 500. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"01K80EAX90JN8RYN7DAN97Q2FQ\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:227\n",
      "\n",
      "  \u001b[2m2025-10-20T09:13:49.115104Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #3. Sleeping 6.513569352s before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n",
      "  \u001b[2m2025-10-20T09:13:55.730915Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 500. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"01K80EB3QSYD9602PNEM3342W9\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:227\n",
      "\n",
      "  \u001b[2m2025-10-20T09:13:55.730972Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #4. Sleeping 37.351883073s before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n",
      "  \u001b[2m2025-10-20T09:14:33.186633Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 500. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"01K80EC8A7JRBBY03VC34HP5KE\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:227\n",
      "\n",
      "  \u001b[2m2025-10-20T09:14:33.538066Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 500. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"01K80EC8N852BF65B866KPSG5J\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:227\n",
      "\n",
      "  \u001b[2m2025-10-20T09:14:33.538084Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #0. Sleeping 1.887832104s before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n",
      "  \u001b[2m2025-10-20T09:14:35.530282Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 500. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"01K80ECAKE45A6RKYHAXDWJX90\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:227\n",
      "\n",
      "  \u001b[2m2025-10-20T09:14:35.530301Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #1. Sleeping 5.924861962s before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n",
      "  \u001b[2m2025-10-20T09:14:41.559888Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 500. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"01K80ECGFYN632M7EMMGCZJWC5\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:227\n",
      "\n",
      "  \u001b[2m2025-10-20T09:14:41.559903Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #2. Sleeping 8.503586411s before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n",
      "  \u001b[2m2025-10-20T09:14:50.169859Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 500. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"01K80ECRWV5G2RFJKK68TZ4KHG\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:227\n",
      "\n",
      "  \u001b[2m2025-10-20T09:14:50.169907Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #3. Sleeping 1.305118771s before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n",
      "  \u001b[2m2025-10-20T09:14:51.579074Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 500. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"01K80ECT91E6K0JBFPYBTCZZD3\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:227\n",
      "\n",
      "  \u001b[2m2025-10-20T09:14:51.579087Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #4. Sleeping 37.648265739s before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n",
      "  \u001b[2m2025-10-20T09:15:29.328790Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 500. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"01K80EDZ4R9WYZDKNJQVXD9A79\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:227\n",
      "\n",
      "  \u001b[2m2025-10-20T09:15:29.811056Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 500. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"01K80EDZKSTMV5SQ4E6SP53PKS\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:227\n",
      "\n",
      "  \u001b[2m2025-10-20T09:15:29.811067Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #0. Sleeping 1.42266668s before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n",
      "  \u001b[2m2025-10-20T09:15:31.337526Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 500. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"01K80EE13FGDS5B094HA0T4BBE\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:227\n",
      "\n",
      "  \u001b[2m2025-10-20T09:15:31.337554Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #1. Sleeping 13.21375ms before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n",
      "  \u001b[2m2025-10-20T09:15:31.455474Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 500. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"01K80EE173M0N2CM95K3V3W0S8\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:227\n",
      "\n",
      "  \u001b[2m2025-10-20T09:15:31.455485Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #2. Sleeping 625.536904ms before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n",
      "  \u001b[2m2025-10-20T09:15:32.183518Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 500. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"01K80EE1XX689KE62NYESVA868\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:227\n",
      "\n",
      "  \u001b[2m2025-10-20T09:15:32.183572Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #3. Sleeping 5.106298452s before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n",
      "  \u001b[2m2025-10-20T09:15:37.394001Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 500. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"01K80EE70P62GRN8RM7T20B8GW\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:227\n",
      "\n",
      "  \u001b[2m2025-10-20T09:15:37.394014Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #4. Sleeping 25.349800709s before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n",
      "  \u001b[2m2025-10-20T09:16:02.852014Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 500. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"01K80EEZW9BFYFRNARKFG2XG1M\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:227\n",
      "\n",
      "  \u001b[2m2025-10-20T09:16:03.342588Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 500. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"01K80EF0BJTRBFFGWPY91HMJ27\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:227\n",
      "\n",
      "  \u001b[2m2025-10-20T09:16:03.342636Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #0. Sleeping 1.82430925s before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n",
      "  \u001b[2m2025-10-20T09:16:05.272720Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 500. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"01K80EF27WQ7XVRMYK4SMF55PN\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:227\n",
      "\n",
      "  \u001b[2m2025-10-20T09:16:05.272790Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #1. Sleeping 4.232882423s before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n",
      "  \u001b[2m2025-10-20T09:16:09.609379Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 500. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"01K80EF6FFR7MTN7B5MF5SYGJ4\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:227\n",
      "\n",
      "  \u001b[2m2025-10-20T09:16:09.609411Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #2. Sleeping 11.078797383s before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n",
      "  \u001b[2m2025-10-20T09:16:20.794442Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 500. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"01K80EFHCXRMCVK1B4NJ4723FY\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:227\n",
      "\n",
      "  \u001b[2m2025-10-20T09:16:20.794468Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #3. Sleeping 9.378916578s before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n",
      "  \u001b[2m2025-10-20T09:16:30.275844Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 500. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"01K80EFTN9P6ZV72935A0CR57A\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:227\n",
      "\n",
      "  \u001b[2m2025-10-20T09:16:30.275858Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #4. Sleeping 24.170703222s before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n",
      "  \u001b[2m2025-10-20T09:16:54.557030Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 500. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"01K80EGJBZY1VB12ZY9C4Q9M37\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:227\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not load model MoritzLaurer/mDeBERTa-v3-base-mnli-xnli with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSequenceClassification'>, <class 'transformers.models.deberta_v2.modeling_deberta_v2.DebertaV2ForSequenceClassification'>). See the original errors:\n\nwhile loading with AutoModelForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 1037, in _get_resolved_checkpoint_files\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/utils/hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/utils/hub.py\", line 567, in cached_files\n    raise e\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/utils/hub.py\", line 479, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 1010, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 1171, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 1723, in _download_to_tmp_and_move\n    xet_get(\n    ~~~~~~~^\n        incomplete_path=incomplete_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        displayed_filename=filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 629, in xet_get\n    download_files(\n    ~~~~~~~~~~~~~~^\n        xet_download_info,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        progress_updater=[progress_updater],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\nRuntimeError: Data processing error: CAS service error : Reqwest Error: HTTP status server error (500 Internal Server Error), domain: https://cas-server.xethub.hf.co/reconstructions/8bded11c3b90feb4aa05526dcb7665950899379207b117a01166aeaa4abf5cfa\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/pipelines/base.py\", line 293, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/models/auto/auto_factory.py\", line 604, in from_pretrained\n    return model_class.from_pretrained(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 277, in _wrapper\n    return func(*args, **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 4900, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 1160, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<5 lines>...\n    ) from e\nOSError: Can't load the model for 'MoritzLaurer/mDeBERTa-v3-base-mnli-xnli'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'MoritzLaurer/mDeBERTa-v3-base-mnli-xnli' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 1037, in _get_resolved_checkpoint_files\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/utils/hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/utils/hub.py\", line 567, in cached_files\n    raise e\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/utils/hub.py\", line 479, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 1010, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 1171, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 1723, in _download_to_tmp_and_move\n    xet_get(\n    ~~~~~~~^\n        incomplete_path=incomplete_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        displayed_filename=filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 629, in xet_get\n    download_files(\n    ~~~~~~~~~~~~~~^\n        xet_download_info,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        progress_updater=[progress_updater],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\nRuntimeError: Data processing error: CAS service error : Reqwest Error: HTTP status server error (500 Internal Server Error), domain: https://cas-server.xethub.hf.co/reconstructions/8bded11c3b90feb4aa05526dcb7665950899379207b117a01166aeaa4abf5cfa\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/pipelines/base.py\", line 311, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/models/auto/auto_factory.py\", line 604, in from_pretrained\n    return model_class.from_pretrained(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 277, in _wrapper\n    return func(*args, **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 4900, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 1160, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<5 lines>...\n    ) from e\nOSError: Can't load the model for 'MoritzLaurer/mDeBERTa-v3-base-mnli-xnli'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'MoritzLaurer/mDeBERTa-v3-base-mnli-xnli' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.\n\nwhile loading with DebertaV2ForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 1037, in _get_resolved_checkpoint_files\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/utils/hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/utils/hub.py\", line 567, in cached_files\n    raise e\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/utils/hub.py\", line 479, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 1010, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 1171, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 1723, in _download_to_tmp_and_move\n    xet_get(\n    ~~~~~~~^\n        incomplete_path=incomplete_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        displayed_filename=filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 629, in xet_get\n    download_files(\n    ~~~~~~~~~~~~~~^\n        xet_download_info,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        progress_updater=[progress_updater],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\nRuntimeError: Data processing error: CAS service error : Reqwest Error: HTTP status server error (500 Internal Server Error), domain: https://cas-server.xethub.hf.co/reconstructions/8bded11c3b90feb4aa05526dcb7665950899379207b117a01166aeaa4abf5cfa\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/pipelines/base.py\", line 293, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 277, in _wrapper\n    return func(*args, **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 4900, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 1160, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<5 lines>...\n    ) from e\nOSError: Can't load the model for 'MoritzLaurer/mDeBERTa-v3-base-mnli-xnli'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'MoritzLaurer/mDeBERTa-v3-base-mnli-xnli' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 1037, in _get_resolved_checkpoint_files\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/utils/hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/utils/hub.py\", line 567, in cached_files\n    raise e\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/utils/hub.py\", line 479, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 1010, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 1171, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 1723, in _download_to_tmp_and_move\n    xet_get(\n    ~~~~~~~^\n        incomplete_path=incomplete_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        displayed_filename=filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 629, in xet_get\n    download_files(\n    ~~~~~~~~~~~~~~^\n        xet_download_info,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        progress_updater=[progress_updater],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\nRuntimeError: Data processing error: CAS service error : Reqwest Error: HTTP status server error (500 Internal Server Error), domain: https://cas-server.xethub.hf.co/reconstructions/8bded11c3b90feb4aa05526dcb7665950899379207b117a01166aeaa4abf5cfa\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/pipelines/base.py\", line 311, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 277, in _wrapper\n    return func(*args, **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 4900, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 1160, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<5 lines>...\n    ) from e\nOSError: Can't load the model for 'MoritzLaurer/mDeBERTa-v3-base-mnli-xnli'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'MoritzLaurer/mDeBERTa-v3-base-mnli-xnli' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 1. Load the pipeline\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading zero-shot pipeline... (This may take a moment)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m clf_zero_shot = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mzero-shot-classification\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMoritzLaurer/mDeBERTa-v3-base-mnli-xnli\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Use GPU if available\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPipeline loaded!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 2. Define candidate labels (we use English for fun, the model is multilingual!)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/pipelines/__init__.py:1027\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1026\u001b[39m     model_classes = {\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m: targeted_task[\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m: targeted_task[\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m]}\n\u001b[32m-> \u001b[39m\u001b[32m1027\u001b[39m     framework, model = \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m        \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1037\u001b[39m hub_kwargs[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m] = model.config._commit_hash\n\u001b[32m   1039\u001b[39m \u001b[38;5;66;03m# Check which preprocessing classes the pipeline uses\u001b[39;00m\n\u001b[32m   1040\u001b[39m \u001b[38;5;66;03m# None values indicate optional classes that the pipeline can run without, we don't raise errors if loading fails\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/pipelines/base.py:333\u001b[39m, in \u001b[36minfer_framework_load_model\u001b[39m\u001b[34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[39m\n\u001b[32m    331\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m class_name, trace \u001b[38;5;129;01min\u001b[39;00m all_traceback.items():\n\u001b[32m    332\u001b[39m             error += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwhile loading with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, an error is thrown:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtrace\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    334\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not load model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with any of the following classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_tuple\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. See the original errors:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    335\u001b[39m         )\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    338\u001b[39m     framework = infer_framework(model.\u001b[34m__class__\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Could not load model MoritzLaurer/mDeBERTa-v3-base-mnli-xnli with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSequenceClassification'>, <class 'transformers.models.deberta_v2.modeling_deberta_v2.DebertaV2ForSequenceClassification'>). See the original errors:\n\nwhile loading with AutoModelForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 1037, in _get_resolved_checkpoint_files\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/utils/hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/utils/hub.py\", line 567, in cached_files\n    raise e\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/utils/hub.py\", line 479, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 1010, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 1171, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 1723, in _download_to_tmp_and_move\n    xet_get(\n    ~~~~~~~^\n        incomplete_path=incomplete_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        displayed_filename=filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 629, in xet_get\n    download_files(\n    ~~~~~~~~~~~~~~^\n        xet_download_info,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        progress_updater=[progress_updater],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\nRuntimeError: Data processing error: CAS service error : Reqwest Error: HTTP status server error (500 Internal Server Error), domain: https://cas-server.xethub.hf.co/reconstructions/8bded11c3b90feb4aa05526dcb7665950899379207b117a01166aeaa4abf5cfa\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/pipelines/base.py\", line 293, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/models/auto/auto_factory.py\", line 604, in from_pretrained\n    return model_class.from_pretrained(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 277, in _wrapper\n    return func(*args, **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 4900, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 1160, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<5 lines>...\n    ) from e\nOSError: Can't load the model for 'MoritzLaurer/mDeBERTa-v3-base-mnli-xnli'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'MoritzLaurer/mDeBERTa-v3-base-mnli-xnli' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 1037, in _get_resolved_checkpoint_files\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/utils/hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/utils/hub.py\", line 567, in cached_files\n    raise e\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/utils/hub.py\", line 479, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 1010, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 1171, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 1723, in _download_to_tmp_and_move\n    xet_get(\n    ~~~~~~~^\n        incomplete_path=incomplete_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        displayed_filename=filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 629, in xet_get\n    download_files(\n    ~~~~~~~~~~~~~~^\n        xet_download_info,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        progress_updater=[progress_updater],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\nRuntimeError: Data processing error: CAS service error : Reqwest Error: HTTP status server error (500 Internal Server Error), domain: https://cas-server.xethub.hf.co/reconstructions/8bded11c3b90feb4aa05526dcb7665950899379207b117a01166aeaa4abf5cfa\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/pipelines/base.py\", line 311, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/models/auto/auto_factory.py\", line 604, in from_pretrained\n    return model_class.from_pretrained(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 277, in _wrapper\n    return func(*args, **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 4900, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 1160, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<5 lines>...\n    ) from e\nOSError: Can't load the model for 'MoritzLaurer/mDeBERTa-v3-base-mnli-xnli'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'MoritzLaurer/mDeBERTa-v3-base-mnli-xnli' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.\n\nwhile loading with DebertaV2ForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 1037, in _get_resolved_checkpoint_files\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/utils/hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/utils/hub.py\", line 567, in cached_files\n    raise e\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/utils/hub.py\", line 479, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 1010, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 1171, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 1723, in _download_to_tmp_and_move\n    xet_get(\n    ~~~~~~~^\n        incomplete_path=incomplete_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        displayed_filename=filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 629, in xet_get\n    download_files(\n    ~~~~~~~~~~~~~~^\n        xet_download_info,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        progress_updater=[progress_updater],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\nRuntimeError: Data processing error: CAS service error : Reqwest Error: HTTP status server error (500 Internal Server Error), domain: https://cas-server.xethub.hf.co/reconstructions/8bded11c3b90feb4aa05526dcb7665950899379207b117a01166aeaa4abf5cfa\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/pipelines/base.py\", line 293, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 277, in _wrapper\n    return func(*args, **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 4900, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 1160, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<5 lines>...\n    ) from e\nOSError: Can't load the model for 'MoritzLaurer/mDeBERTa-v3-base-mnli-xnli'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'MoritzLaurer/mDeBERTa-v3-base-mnli-xnli' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 1037, in _get_resolved_checkpoint_files\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/utils/hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/utils/hub.py\", line 567, in cached_files\n    raise e\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/utils/hub.py\", line 479, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 1010, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 1171, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 1723, in _download_to_tmp_and_move\n    xet_get(\n    ~~~~~~~^\n        incomplete_path=incomplete_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        displayed_filename=filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/huggingface_hub/file_download.py\", line 629, in xet_get\n    download_files(\n    ~~~~~~~~~~~~~~^\n        xet_download_info,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        progress_updater=[progress_updater],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\nRuntimeError: Data processing error: CAS service error : Reqwest Error: HTTP status server error (500 Internal Server Error), domain: https://cas-server.xethub.hf.co/reconstructions/8bded11c3b90feb4aa05526dcb7665950899379207b117a01166aeaa4abf5cfa\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/pipelines/base.py\", line 311, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 277, in _wrapper\n    return func(*args, **kwargs)\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 4900, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/muellersebastian/1math/1teaching/llms-data-science-course/venvLLMDS/lib/python3.13/site-packages/transformers/modeling_utils.py\", line 1160, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<5 lines>...\n    ) from e\nOSError: Can't load the model for 'MoritzLaurer/mDeBERTa-v3-base-mnli-xnli'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'MoritzLaurer/mDeBERTa-v3-base-mnli-xnli' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.\n\n\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the pipeline\n",
    "print(\"Loading zero-shot pipeline... (This may take a moment)\")\n",
    "clf_zero_shot = pipeline(\n",
    "    \"zero-shot-classification\", \n",
    "    model=\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\",\n",
    "    device=0 if torch.cuda.is_available() else -1 # Use GPU if available\n",
    ")\n",
    "print(\"Pipeline loaded!\")\n",
    "\n",
    "# 2. Define candidate labels (we use English for fun, the model is multilingual!)\n",
    "candidate_labels = [\n",
    "    \"student's class schedule\",\n",
    "    \"check student email\",\n",
    "    \"register for new classes\",\n",
    "    \"manage student ID card\",\n",
    "    \"find library information\"\n",
    "]\n",
    "\n",
    "# This maps the descriptive labels back to our short ones\n",
    "label_map_zero_shot = {\n",
    "    \"student's class schedule\": \"get_schedule\",\n",
    "    \"check student email\": \"check_email\",\n",
    "    \"register for new classes\": \"register_classes\",\n",
    "    \"manage student ID card\": \"get_student_card\",\n",
    "    \"find library information\": \"find_library_info\"\n",
    "}\n",
    "\n",
    "# 3. Call the classifier\n",
    "test_query = test_data[0]['text']\n",
    "result = clf_zero_shot(test_query, candidate_labels)\n",
    "\n",
    "# The result is a dictionary, the top label is the first one\n",
    "top_label_desc = result['labels'][0]\n",
    "prediction = label_map_zero_shot[top_label_desc]\n",
    "\n",
    "print(f\"\\nQuery: '{test_query}'\")\n",
    "print(f\"Model's top choice: '{top_label_desc}' (Score: {result['scores'][0]:.2f})\")\n",
    "print(f\"Prediction: {prediction}\")\n",
    "print(f\"Correct: {prediction == test_data[0]['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d00089",
   "metadata": {},
   "source": [
    "### Exploration:\n",
    "This model's performance is *highly* dependent on the `candidate_labels`. What happens if you use our short labels (e.g., `\"get_schedule\"`)? What if you use French descriptions (e.g., `\"emploi du temps\"`)? Which works best?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a30dfa1",
   "metadata": {},
   "source": [
    "---\n",
    "## Module 5: Classifier 4 - The LLM Prompt\n",
    "\n",
    "Time for the SOTA (State-of-the-Art) approach. We'll use a powerful LLM. Instead of *training* it, we will *prompt* it.\n",
    "\n",
    "This is **In-Context Learning**. We'll tell the model what its job is, give it the list of possible labels, and ask it to classify our query. This is the most flexible approach, but often the slowest.\n",
    "\n",
    "### Your Exercise:\n",
    "1.  Create a prompt using our template.\n",
    "2.  Call the pipeline and **parse the output** to get just the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfedd97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to install the Google AI client library\n",
    "%pip install -q google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b915026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini API configured successfully!\n",
      "Gemini 2.5 Flash model loaded. Ready to classify!\n",
      "\n",
      "Running Gemini inference for query: 'C'est quand mon prochain TD?'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1760951131.341271 7440395 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini Raw Output: get_schedule\n",
      "Prediction: get_schedule\n",
      "Correct: True\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# --- This code securely gets your API key --- \n",
    "try:\n",
    "    # Used in Google Colab\n",
    "    from google.colab import userdata\n",
    "    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
    "except ImportError:\n",
    "    # Fallback for local Jupyter/VSCode\n",
    "    GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')\n",
    "\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"API Key not found. Please follow the instructions in the markdown cell above to set 'GOOGLE_API_KEY'.\")\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "print(\"Gemini API configured successfully!\")\n",
    "\n",
    "# --- 2. Create the model and prompt --- \n",
    "\n",
    "# Get the list of labels from our dataframe\n",
    "possible_labels = train_df['label'].unique().tolist()\n",
    "labels_list_str = \", \".join(possible_labels)\n",
    "\n",
    "MODEL_NAME = os.getenv('GEMINI_MODEL', 'gemini-2.5-flash')\n",
    "\n",
    "# With the Gemini API, we use a 'system_instruction' to set the model's behavior\n",
    "SYSTEM_PROMPT = f\"\"\"You are an AMU chatbot assistant. Classify the student's request into exactly one of the following categories: {labels_list_str}\n",
    "Return ONLY the category name and nothing else.\"\"\"\n",
    "\n",
    "# We also set the 'generation_config' to control the output\n",
    "generation_config = genai.types.GenerationConfig(\n",
    "    temperature=0,      # We want deterministic, not creative, answers\n",
    "    max_output_tokens=100 # We only need one or two words for the label\n",
    ")\n",
    "\n",
    "# 3. Initialize the model\n",
    "model_gemini = genai.GenerativeModel(\n",
    "    MODEL_NAME,\n",
    "    system_instruction=SYSTEM_PROMPT,\n",
    "    generation_config=generation_config\n",
    ")\n",
    "\n",
    "print(f\"Gemini 2.5 Flash model loaded. Ready to classify!\")\n",
    "\n",
    "\n",
    "# --- 4. Call the API and parse --- \n",
    "test_index = 0\n",
    "test_query = test_data[test_index]['text']\n",
    "print(f\"\\nRunning Gemini inference for query: '{test_query}'...\")\n",
    "\n",
    "try:\n",
    "    # This is the actual API call!\n",
    "    response = model_gemini.generate_content(test_query)\n",
    "    \n",
    "    # The API response is clean, no more .split() needed!\n",
    "    prediction = response.text.strip()\n",
    "\n",
    "    print(f\"Gemini Raw Output: {response.text}\")\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "    print(f\"Correct: {prediction == test_data[test_index]['label']}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"This may be due to a missing API key or safety settings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b86cb61",
   "metadata": {},
   "source": [
    "### Exploration:\n",
    "Prompt engineering is an art. How does the model's accuracy change if you change the system prompt? What if you give it two examples in the prompt (this is called \"few-shot\" prompting)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d76160",
   "metadata": {},
   "source": [
    "---\n",
    "## Module 6: The Showdown!\n",
    "\n",
    "It's time to compare our four champions. We will loop through our entire `test_data` and run all four classifiers on each query. We'll record their `prediction` and their `latency` (speed).\n",
    "\n",
    "### Your Exercise:\n",
    "Fill in the loop below. We've provided the structure. You need to call each of your classifiers and time them using `time.perf_counter()`.\n",
    "\n",
    "**Note:** For a fair *latency* comparison, we should test on a CPU. But for the *accuracy* part, using a GPU for the slow models is fine. For simplicity, we'll just test on whatever device you have. Be aware that the LLM/Zero-Shot latencies will be *much* lower on a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272df0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "print(f\"Running benchmarks on {len(test_data)} test items...\")\n",
    "\n",
    "for item in test_data:\n",
    "    query = item['text']\n",
    "    correct_label = item['label']\n",
    "\n",
    "    # --- 1. Regex ---\n",
    "    start_time = time.perf_counter()\n",
    "    pred_regex = classify_regex(query)\n",
    "    end_time = time.perf_counter()\n",
    "    results.append({\n",
    "        \"classifier\": \"Regex\",\n",
    "        \"query\": query,\n",
    "        \"prediction\": pred_regex,\n",
    "        \"correct\": pred_regex == correct_label,\n",
    "        \"latency_ms\": (end_time - start_time) * 1000\n",
    "    })\n",
    "\n",
    "    # --- 2. Embed + LogReg ---\n",
    "    start_time = time.perf_counter()\n",
    "    query_embedding = get_embeddings([query])\n",
    "    pred_logreg = clf_logreg.predict(query_embedding)[0]\n",
    "    end_time = time.perf_counter()\n",
    "    results.append({\n",
    "        \"classifier\": \"Embed + LogReg\",\n",
    "        \"query\": query,\n",
    "        \"prediction\": pred_logreg,\n",
    "        \"correct\": pred_logreg == correct_label,\n",
    "        \"latency_ms\": (end_time - start_time) * 1000\n",
    "    })\n",
    "\n",
    "    # --- 3. Zero-Shot Pipeline ---\n",
    "    start_time = time.perf_counter()\n",
    "    res_zero_shot = clf_zero_shot(query, candidate_labels)\n",
    "    pred_zero_shot = label_map_zero_shot[res_zero_shot['labels'][0]]\n",
    "    end_time = time.perf_counter()\n",
    "    results.append({\n",
    "        \"classifier\": \"Zero-Shot Pipe\",\n",
    "        \"query\": query,\n",
    "        \"prediction\": pred_zero_shot,\n",
    "        \"correct\": pred_zero_shot == correct_label,\n",
    "        \"latency_ms\": (end_time - start_time) * 1000\n",
    "    })\n",
    "\n",
    "    # --- 4. Gemini API ---\n",
    "    start_time = time.perf_counter()\n",
    "    try:\n",
    "        # We re-use the 'model_gemini' we configured in Module 5\n",
    "        response = model_gemini.generate_content(query)\n",
    "        pred_llm = response.text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Gemini API error on query '{query}': {e}\")\n",
    "        pred_llm = \"API_ERROR\" # So we can see failures\n",
    "    end_time = time.perf_counter()\n",
    "    \n",
    "    results.append({\n",
    "        \"classifier\": \"Gemini API\", # Renamed\n",
    "        \"query\": query,\n",
    "        \"prediction\": pred_llm,\n",
    "        \"correct\": pred_llm == correct_label,\n",
    "        \"latency_ms\": (end_time - start_time) * 1000\n",
    "    })\n",
    "\n",
    "print(\"Benchmarks complete!\")\n",
    "\n",
    "# Convert to a DataFrame for analysis\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcd3635",
   "metadata": {},
   "source": [
    "### Final Analysis: Accuracy and Speed\n",
    "\n",
    "Now for the final step. Let's group by our classifiers and calculate two things:\n",
    "1.  **Accuracy**: The mean of the `correct` column (True=1, False=0).\n",
    "2.  **Avg. Latency**: The mean of the `latency_ms` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89f2476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to fix any LLM predictions that didn't give a valid label\n",
    "valid_labels = set(possible_labels)\n",
    "def validate_label(row):\n",
    "    if row['classifier'] == 'LLM Prompt' and row['prediction'] not in valid_labels:\n",
    "        return False # Mark as incorrect if the label isn't in our list\n",
    "    return row['correct']\n",
    "\n",
    "results_df['correct'] = results_df.apply(validate_label, axis=1)\n",
    "\n",
    "# Now, let's calculate our final metrics\n",
    "final_report = results_df.groupby('classifier').agg(\n",
    "    Accuracy=pd.NamedAgg(column='correct', aggfunc='mean'),\n",
    "    Avg_Latency_ms=pd.NamedAgg(column='latency_ms', aggfunc='mean')\n",
    ").sort_values(by='Accuracy', ascending=False)\n",
    "\n",
    "# Format for nice printing\n",
    "final_report['Accuracy'] = final_report['Accuracy'].apply(lambda x: f\"{x*100:.2f}%\")\n",
    "final_report['Avg_Latency_ms'] = final_report['Avg_Latency_ms'].apply(lambda x: f\"{x:.2f} ms\")\n",
    "\n",
    "display(Markdown(\"## Final Report Card\"))\n",
    "display(final_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eaaac4",
   "metadata": {},
   "source": [
    "## Conclusion & Your Turn\n",
    "\n",
    "Look at your final report. What do you see?\n",
    "\n",
    "* **Regex** is by far the **fastest**, but likely the least accurate (and will get worse as queries get more complex).\n",
    "* **Embed + LogReg** is the perfect balance: **very fast** (once trained) and **very accurate**. s Downsides are that it needs good training data and adding new intent requires new training. \n",
    "* **Zero-Shot Pipe** is amazing for a **prototype** (good accuracy, no training!), but it's much slower.\n",
    "* **LLM Prompt** is likely the **most accurate** and flexible (it can handle typos and complex phrasing!), but it is by far the **slowest**.\n",
    "\n",
    "### Final Question:\n",
    "\n",
    "If you were building the *real* AMU chatbot, which would you choose? \n",
    "\n",
    "*(Hint: There's no single right answer. A great system might use a **hybrid**! Try Regex first for simple keywords, and if it doesn't find a match, pass the query to the `Embed + LogReg` model. This gives you the speed of Regex and the power of ML!)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venvLLMDS)",
   "language": "python",
   "name": "venvllmds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
